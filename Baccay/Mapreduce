from pyspark.sql import functions as F

# MAP → each row implicitly emits:
# key = (year, month)
# value = (1, duration_min, radiant_win)

mapreduce_df = matches_features.groupBy("year", "month") \
    .agg(
        F.count("*").alias("match_count"),
        F.avg("duration_min").alias("avg_duration"),
        F.avg(F.col("radiant_win").cast("int")).alias("win_rate")
    ) \
    .orderBy("year", "month")

mapreduce_df.show(10)

# Physical Plan
mapreduce_df.explain(True)

# Save a small part
mapreduce_df.write.mode("overwrite") \
    .option("header", True) \
    .csv("/home/john/bigdata_project/bigdata/bigdata_project/opendota_processed/9/data/activity_summary")

# Mapreduce Diagram
plt.figure(figsize=(9,4))

plt.text(0.05, 0.5, "MAP\nEmit (year,month)\n→ (1,duration,win)", fontsize=11)
plt.text(0.4, 0.5, "SHUFFLE\nExchange\nGroup by key", fontsize=11)
plt.text(0.75, 0.5, "REDUCE\nAggregate\ncount/avg", fontsize=11)

plt.arrow(0.28, 0.5, 0.08, 0, head_width=0.05)
plt.arrow(0.63, 0.5, 0.08, 0, head_width=0.05)

plt.axis("off")
plt.title("Spark Map → Shuffle → Reduce Execution")

plt.savefig("/home/john/bigdata_project/bigdata/bigdata_project/opendota_processed/9/figures/Mapreduce_diagram.png")
plt.show()

# Spark UI
print("Spark UI:", spark.sparkContext.uiWebUrl)
